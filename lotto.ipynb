{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('lotto.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values  # Features (historical numbers)\n",
    "y = data.iloc[:, -1].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 5ms/step - loss: 748.2950\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 693.8317\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 639.2413\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 582.9266\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 523.3546\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 464.1869\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 403.0413\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 343.7306\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 287.1412\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 237.6429\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 199.1551\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 166.6599\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 149.3867\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 145.1344\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 140.6345\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 137.6108\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 133.6367\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 129.8414\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 126.0266\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 121.9581\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 118.3077\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 115.0664\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 112.3249\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 109.8324\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 108.5832\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 107.5746\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 105.2815\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 102.7274\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 100.8948\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 100.3219\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 99.2875\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 97.7824\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 96.4943\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 95.2572\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 94.3211\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 93.4861\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 92.5936\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 91.9100\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 91.5942\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 90.6852\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 90.2082\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 89.8837\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 89.4303\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 88.6042\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 87.9374\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 87.7975\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 87.1546\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 86.7020\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 86.3891\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 85.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21bdf88ceb0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 450ms/step - loss: 118.2209\n",
      "Test Loss: 118.220947265625\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 361ms/step\n"
     ]
    }
   ],
   "source": [
    "last_sequence = X_test[-1]\n",
    "next_numbers = model.predict(np.reshape(last_sequence, (1, 1, X_test.shape[2])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jomna\\Documents\\GitHub\\Data-Analysis-R\\lotto.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jomna/Documents/GitHub/Data-Analysis-R/lotto.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Inverse transform to get the original scale\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jomna/Documents/GitHub/Data-Analysis-R/lotto.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predicted_numbers \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49minverse_transform(next_numbers)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jomna/Documents/GitHub/Data-Analysis-R/lotto.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predicted_numbers \u001b[39m=\u001b[39m predicted_numbers[\u001b[39m0\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m6\u001b[39m:]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jomna/Documents/GitHub/Data-Analysis-R/lotto.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPredicted Next Numbers:\u001b[39m\u001b[39m\"\u001b[39m, predicted_numbers)\n",
      "File \u001b[1;32mc:\\Users\\jomna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1035\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_std:\n\u001b[1;32m-> 1035\u001b[0m         X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[0;32m   1036\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n\u001b[0;32m   1037\u001b[0m         X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,5)"
     ]
    }
   ],
   "source": [
    "# Inverse transform to get the original scale\n",
    "predicted_numbers = scaler.inverse_transform(next_numbers)\n",
    "predicted_numbers = predicted_numbers[0][-6:]\n",
    "print(\"Predicted Next Numbers:\", predicted_numbers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
