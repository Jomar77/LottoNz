{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "\n",
    "# Specify the file name\n",
    "file_name = [\"powerball.csv\", \"lotto.csv\", \"output.csv\"]\n",
    "\n",
    "# Check if file exists then delete it\n",
    "for i in range(0, len(file_name)):\n",
    "    if os.path.exists(file_name[i]):\n",
    "        os.remove(file_name[i])\n",
    "        print(f\"{file_name[i]} has been deleted.\")\n",
    "    else:\n",
    "        print(\"The file does not exist.\")\n",
    "\n",
    "# create a loop for month names\n",
    "for month in range(12):\n",
    "    months = [\n",
    "        \"january\",\n",
    "        \"february\",\n",
    "        \"march\",\n",
    "        \"april\",\n",
    "        \"may\",\n",
    "        \"june\",\n",
    "        \"july\",\n",
    "        \"august\",\n",
    "        \"september\",\n",
    "        \"october\",\n",
    "        \"november\",\n",
    "        \"december\",\n",
    "    ]\n",
    "\n",
    "    for year in range(5):\n",
    "        years = ['2015','2016','2017','2018','2019', '2020', '2021', '2022', '2023']\n",
    "    # URL of the website you want to scrape\n",
    "        url = \"http://lottoresults.co.nz/lotto/\" + months[month] +\"-\" + years[year]\n",
    "# url = \"http://lottoresults.co.nz/lotto/\" + months[month] + \"-2023\"\n",
    "\n",
    "    # Send an HTTP GET request to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        article_titles = soup.find_all(\"li\", class_=\"draw-result__ball\")\n",
    "        list = []\n",
    "        # Loop through the article titles and add them to the list\n",
    "        for title in article_titles:\n",
    "            list.append(title.text.strip())\n",
    "\n",
    "        # seperate the list into tuples of 6\n",
    "        list = reversed([tuple(list[i : i + 6]) for i in range(0, len(list), 6)])\n",
    "\n",
    "        # write it in a csv file\n",
    "        import csv\n",
    "\n",
    "        with open(\"lotto.csv\", \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(list)\n",
    "\n",
    "        pball_list=[]\n",
    "        article_titles = soup.find_all(\"li\", class_=\"draw-result__ball\")\n",
    "        # Loop through the article titles and add every 12th item starting from index 7 to the list\n",
    "        for i in range(7, len(article_titles), 12):\n",
    "            pball_list.append(article_titles[i].text.strip())\n",
    "\n",
    "        with open(\"powerball.csv\", \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(pball_list)\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "input_file = \"lotto.csv\"\n",
    "output_file = \"output.csv\"\n",
    "\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\", newline=\"\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    for i, row in enumerate(reader, start=1):\n",
    "        if i % 2 == 1:\n",
    "            # Delete content from even-numbered lines\n",
    "            row = [\"\"] * len(row)\n",
    "\n",
    "        # Check if any element in the row is non-empty\n",
    "        if any(cell.strip() for cell in row):\n",
    "            writer.writerow(row)\n",
    "\n",
    "print(\"Empty lines removed from even-numbered lines.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
